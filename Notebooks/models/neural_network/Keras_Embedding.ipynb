{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "from utils.schemas import schema_train_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "\n",
    "Para cargar los datos con pandas, voy a usar la misma forma que usamos en LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_4.zip  df_num    test_final_4  train_final_4\r\n",
      "df_cat\t    test.csv  train.csv     train_model_little.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../../../data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUTA_TRAIN = \"../../../data/train_final_4/\"\n",
    "RUTA_TEST = \"../../../data/test_final_4/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Cargando datos del TRAIN')\n",
    "# path = RUTA_TRAIN\n",
    "# allFiles = glob.glob(path + \"/*.csv\")\n",
    "# list_ = []\n",
    "# for file_ in allFiles:\n",
    "#     df = pd.read_csv(file_)\n",
    "#     df = (df.fillna(-1)).astype(schema_train_4)\n",
    "#     list_.append(df)\n",
    "\n",
    "# train = pd.concat(list_, axis = 0, ignore_index= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(RUTA_TRAIN)\n",
    "# df = (df.fillna(0)).astype(schema_train_4)\n",
    "df = (df).astype(schema_train_4)\n",
    "\n",
    "\n",
    "#train = df\n",
    "# train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "categoric_features = ['ProductName_index','EngineVersion_0_index','EngineVersion_1_index','Census_OSVersion_0_index','Census_OSVersion_1_index','AppVersion_0_index','AppVersion_1_index','AvSigVersion_0_index','AvSigVersion_1_index','OsVer_0_index','OsVer_1_index','Platform_index','Processor_index','OsPlatformSubRelease_index','OsBuildLab_index','SkuEdition_index','PuaMode_index','SmartScreen_index','Census_MDC2FormFactor_index','Census_DeviceFamily_index','Census_ProcessorClass_index','Census_PrimaryDiskTypeName_index','Census_ChassisTypeName_index','Census_PowerPlatformRoleName_index','Census_InternalBatteryType_index','Census_OSArchitecture_index','Census_OSBranch_index','Census_OSEdition_index','Census_OSSkuName_index','Census_OSInstallTypeName_index','Census_OSWUAutoUpdateOptionsName_index','Census_GenuineStateName_index','Census_ActivationChannel_index','Census_FlightRing_index','OsVer_index','DefaultBrowsersIdentifier','AVProductStatesIdentifier','CountryIdentifier','CityIdentifier','OrganizationIdentifier','GeoNameIdentifier','LocaleEnglishNameIdentifier','IeVerIdentifier','Census_OEMNameIdentifier','Census_OEMModelIdentifier','Census_ProcessorManufacturerIdentifier','Census_ProcessorModelIdentifier','Census_OSInstallLanguageIdentifier','Census_OSUILocaleIdentifier','Census_FirmwareManufacturerIdentifier','Census_FirmwareVersionIdentifier','Wdft_RegionIdentifier','RtpStateBitfield','prediction_2','prediction_4','prediction_8','prediction_16','prediction_32','prediction_64']\n",
    "\n",
    "booleans_features = ['Census_IsSecureBootEnabled','Census_IsWIMBootEnabled','Census_IsVirtualDevice','Census_IsTouchEnabled','Census_IsPenCapable','Census_IsAlwaysOnAlwaysConnectedCapable','Wdft_IsGamer','Census_IsPortableOperatingSystem','Census_IsFlightingInternal','Census_IsFlightsDisabled','IsProtected','IsBeta','IsSxsPassiveMode','AVProductsInstalled','AVProductsEnabled','HasTpm','Census_HasOpticalDiskDrive','Census_ThresholdOptIn','Census_InternalBatteryType_informed','Firewall','SMode','AutoSampleOptIn']\n",
    "\n",
    "numerics_features = ['OsBuild','OsSuite','UacLuaenable','Census_ProcessorCoreCount','Census_PrimaryDiskTotalCapacity','Census_SystemVolumeTotalCapacity','Census_TotalPhysicalRAM','Census_InternalPrimaryDiagonalDisplaySizeInInches','Census_InternalPrimaryDisplayResolutionHorizontal','Census_InternalPrimaryDisplayResolutionVertical','Census_InternalBatteryNumberOfCharges','Census_OSBuildNumber','Census_OSBuildRevision','OsBuildLab_diff','std_diff_DateOsBuildLab','AvSigVersion_diff','std_diff_AvSigVersion','OSVersion_diff','std_diff_OSVersion','max_OsBuildLab_diff','max_AvSigVersion_diff','max_OSVersion_diff','ratio_OsBuildLab_diff','ratio_AvSigVersion_diff','ratio_OSVersion_diff','count(DISTINCT AvSigVersion_Name)','count(DISTINCT AvSigVersion_Type)','count(DISTINCT AvSigVersion_AlertLevel)','count1','count2','count3','count4','count5','count6','count7','count8']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__FOR TEST ONLY__\n",
    "\n",
    "Select only features with < 100 categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features_selected = []\n",
    "\n",
    "for i in categoric_features:\n",
    "    if df[i].nunique() < 100:\n",
    "        categorical_features_selected.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change -1 values by 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrganizationIdentifier\n",
      "RtpStateBitfield\n"
     ]
    }
   ],
   "source": [
    "columns_bad = []\n",
    "for i in categorical_features_selected:\n",
    "    if(len(df[df[i] == -1].values)) > 0:\n",
    "        print(i)\n",
    "        columns_bad.append(i)\n",
    "    \n",
    "        \n",
    "\n",
    "for i in columns_bad:\n",
    "     df.loc[df[i] == -1,i] = 99\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change df to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate X and Y "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove cols that not improve the lgbm model, and MachineIdentifier, and HasDetection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_version = ['AvSigVersion_index', 'EngineVersion_index', 'Census_OSVersion_index', 'AppVersion_index']\n",
    "\n",
    "sel_cols = [c for c in train.columns if c not in ['MachineIdentifier',\n",
    "                                                      'HasDetections',\n",
    "                                                      'Census_DeviceFamily_Windows.Server',\n",
    "                                                      'Census_DeviceFamily_Windows.Desktop'\n",
    "                                                     ]+drop_version]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.loc[:, sel_cols]\n",
    "y = train.loc[:,'HasDetections']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train :(89188, 117)\n",
      "X_test :(22298, 117)\n",
      "y_train :(89188,)\n",
      "y_test :(22298,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train :\"+str(X_train.shape))\n",
    "print(\"X_test :\"+str(X_test.shape))\n",
    "print(\"y_train :\"+str(y_train.shape))\n",
    "print(\"y_test :\"+str(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense,Dropout,Embedding,Input,Concatenate,Reshape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUC 1\n",
    "\n",
    "Easy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "import tensorflow as tf\n",
    "\n",
    "def auroc(y_true, y_pred):\n",
    "    return tf.py_func(roc_auc_score, (y_true, y_pred), tf.double)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUC 2\n",
    "\n",
    "For Keras.\n",
    "\n",
    "A little more complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import callbacks\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "class printAUC(callbacks.Callback):\n",
    "    def __init__(self, X_train, y_train):\n",
    "        super(printAUC, self).__init__()\n",
    "        self.bestAUC = 0\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        pred = self.model.predict(np.array(self.X_train))\n",
    "        auc = roc_auc_score(self.y_train, pred)\n",
    "        print(\"Train AUC: \" + str(auc))\n",
    "        pred = self.model.predict(self.validation_data[0])\n",
    "        auc = roc_auc_score(self.validation_data[1], pred)\n",
    "        print (\"Validation AUC: \" + str(auc))\n",
    "        if (self.bestAUC < auc) :\n",
    "            self.bestAUC = auc\n",
    "            self.model.save(\"bestNet.h5\", overwrite=True)\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyStopping = keras.callbacks.EarlyStopping(monitor='auroc', patience=20, verbose=2,min_delta=0.01, mode='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Embedding Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a NN example. I got from Kaggle\n",
    "\n",
    "```py\n",
    "input_numeric = Input(shape=(24,))\n",
    "embedding_numeric = Dense(16)(input_numeric) \n",
    "inputs.append(input_numeric)\n",
    "embeddings.append(embedding_numeric)\n",
    "\n",
    "x = Concatenate()(embeddings)\n",
    "x = Dense(80, activation='relu')(x)\n",
    "x = Dropout(.35)(x)\n",
    "x = Dense(20, activation='relu')(x)\n",
    "x = Dropout(.15)(x)\n",
    "x = Dense(10, activation='relu')(x)\n",
    "x = Dropout(.15)(x)\n",
    "output = Dense(1, activation='sigmoid')(x)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ins = []\n",
    "outs = []\n",
    "for i in categorical_features_selected:\n",
    "    x = Input(shape=(1,),name='input_'+i)\n",
    "    ins.append(x)\n",
    "    x = Embedding(df[i].max()+1, df[i].max()+1, input_length=1,name='embedding_'+i)(x)\n",
    "    x = Reshape(name='reshape_'+i,target_shape=(df[i].max()+1,))(x)\n",
    "    outs.append(x)\n",
    "    \n",
    "# for i in booleanas:\n",
    "#     x = Input(shape=(1,))\n",
    "#     ins.append(x)   \n",
    "#     x = Embedding(df[i].nunique(), df[i].nunique(), input_length=1)(x)\n",
    "#     x = Reshape(target_shape=(df[i].nunique(),))(x)\n",
    "#     outs.append(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "primer_input_len = len(numericas+booleanas)\n",
    "primer_input_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_batch_size = int(X_train.shape[0]/1000)\n",
    "epochs_to_train = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cat_inp = Input(shape=(primer_input_len, ),name=\"Categoricas_Booleanas\")\n",
    "ins.append(cat_inp)\n",
    "# x = Dense(50)(x) \n",
    "# outs.append(x)\n",
    "\n",
    "x = Concatenate()(outs)\n",
    "\n",
    "x = Concatenate()([x,cat_inp])\n",
    "\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(.2)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(.1)(x)\n",
    "output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=ins, outputs=output)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam',metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"modelo3.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FIT!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 89188 samples, validate on 22298 samples\n",
      "Epoch 1/5\n",
      "89188/89188 [==============================] - 21s 231us/step - loss: 8.0491 - acc: 0.4993 - val_loss: 8.0771 - val_acc: 0.4989\n",
      "Epoch 2/5\n",
      "89188/89188 [==============================] - 18s 204us/step - loss: 8.0585 - acc: 0.5000 - val_loss: 8.0771 - val_acc: 0.4989\n",
      "Epoch 3/5\n",
      "89188/89188 [==============================] - 18s 204us/step - loss: 8.0585 - acc: 0.5000 - val_loss: 8.0771 - val_acc: 0.4989\n",
      "Epoch 4/5\n",
      "89188/89188 [==============================] - 18s 204us/step - loss: 8.0585 - acc: 0.5000 - val_loss: 8.0771 - val_acc: 0.4989\n",
      "Epoch 5/5\n",
      "89188/89188 [==============================] - 18s 204us/step - loss: 8.0585 - acc: 0.5000 - val_loss: 8.0771 - val_acc: 0.4989\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x154648438>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit( [X_train[col] for col in categoricas_selected] +  [X_train[numericas+booleanas]], \n",
    "           y_train,\n",
    "          epochs=epochs_to_train,\n",
    "           validation_data = ([X_test[col] for col in categoricas_selected] +  [X_test[numericas+booleanas]],y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "ANN Visualizer: Layer not supported for visualizing",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-f07f0b7f22e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mann_visualizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mann_viz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mann_viz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"NN sin densidad\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/stuff_workspace/2_Kaggle/kaggle_microsoft/enviroment/lib/python3.6/site-packages/ann_visualizer/visualize.py\u001b[0m in \u001b[0;36mann_viz\u001b[0;34m(model, view, filename, title)\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Image\\n\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mpxls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\" x\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mpxls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\" pixels\\n\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mclrmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"white\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ANN Visualizer: Layer not supported for visualizing\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_layers_nr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubgraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cluster_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: ANN Visualizer: Layer not supported for visualizing"
     ]
    }
   ],
   "source": [
    "from ann_visualizer.visualize import ann_viz\n",
    "\n",
    "ann_viz(model, title=\"NN sin densidad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(model.history.history['loss'],label=\"Loss\")\n",
    "plt.plot(model.history.history['auroc'],label=\"acc\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(model.history.history['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(model.history.history['auroc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Cargando datos del TEST')\n",
    "# path = '../../data/test_final_3'\n",
    "# allFiles = glob.glob(path + \"/*.csv\")\n",
    "# list_ = []\n",
    "# for file_ in allFiles:\n",
    "#     df = pd.read_csv(file_)\n",
    "#     df = (df.fillna(-1)).astype(schema_train_3)\n",
    "#     list_.append(df)\n",
    "\n",
    "\n",
    "# test = pd.concat(list_, axis = 0, ignore_index = True).fillna(-1)\n",
    "\n",
    "# sel_cols = [c for c in test.columns if c not in ['MachineIdentifier',\n",
    "#                                                  'HasDetections',\n",
    "#                                                  'Census_DeviceFamily_Windows.Server',\n",
    "#                                                  'Census_DeviceFamily_Windows.Desktop'\n",
    "#                                                  ]\n",
    "#             ]\n",
    "\n",
    "# X_test = test.loc[:, sel_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predf= pd.DataFrame(predictions,columns=['HasDetections'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.concat([X_machines,predf],axis=1).to_csv('keras_model.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_machines = test.loc[:, 'MachineIdentifier']\n",
    "\n",
    "\n",
    "# df_prds = pd.DataFrame({'MachineIdentifier': X_machines, 'HasDetections': predictions})\n",
    "\n",
    "# df_prds.to_csv('keras_model.csv', index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
